{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/home/frizzyzy/Downloads/houseprice.csv\", usecols=[\"SalePrice\", \"MSSubClass\", \"MSZoning\", \"LotFrontage\", \"LotArea\", \"Street\", \"YearBuilt\", \"LotShape\", \"1stFlrSF\", \"2ndFlrSF\"]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1201, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>2003</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>1976</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>2001</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>1915</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>2000</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  YearBuilt  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg       2003   \n",
       "1          20       RL         80.0     9600   Pave      Reg       1976   \n",
       "2          60       RL         68.0    11250   Pave      IR1       2001   \n",
       "3          70       RL         60.0     9550   Pave      IR1       1915   \n",
       "4          60       RL         84.0    14260   Pave      IR1       2000   \n",
       "\n",
       "   1stFlrSF  2ndFlrSF  SalePrice  \n",
       "0       856       854     208500  \n",
       "1      1262         0     181500  \n",
       "2       920       866     223500  \n",
       "3       961       756     140000  \n",
       "4      1145      1053     250000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1201 entries, 0 to 1459\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MSSubClass   1201 non-null   int64  \n",
      " 1   MSZoning     1201 non-null   object \n",
      " 2   LotFrontage  1201 non-null   float64\n",
      " 3   LotArea      1201 non-null   int64  \n",
      " 4   Street       1201 non-null   object \n",
      " 5   LotShape     1201 non-null   object \n",
      " 6   YearBuilt    1201 non-null   int64  \n",
      " 7   1stFlrSF     1201 non-null   int64  \n",
      " 8   2ndFlrSF     1201 non-null   int64  \n",
      " 9   SalePrice    1201 non-null   int64  \n",
      "dtypes: float64(1), int64(6), object(3)\n",
      "memory usage: 103.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name MSSubClass and unique values are 15\n",
      "Column name MSZoning and unique values are 5\n",
      "Column name LotFrontage and unique values are 110\n",
      "Column name LotArea and unique values are 869\n",
      "Column name Street and unique values are 2\n",
      "Column name LotShape and unique values are 4\n",
      "Column name YearBuilt and unique values are 112\n",
      "Column name 1stFlrSF and unique values are 678\n",
      "Column name 2ndFlrSF and unique values are 368\n",
      "Column name SalePrice and unique values are 597\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(f\"Column name {i} and unique values are {len(df[i].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.now().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total years']=datetime.datetime.now().year-df['YearBuilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"YearBuilt\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'LotShape', '1stFlrSF', '2ndFlrSF', 'SalePrice', 'Total years'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Total years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>208500</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>223500</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>140000</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>250000</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  1stFlrSF  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg       856   \n",
       "1          20       RL         80.0     9600   Pave      Reg      1262   \n",
       "2          60       RL         68.0    11250   Pave      IR1       920   \n",
       "3          70       RL         60.0     9550   Pave      IR1       961   \n",
       "4          60       RL         84.0    14260   Pave      IR1      1145   \n",
       "\n",
       "   2ndFlrSF  SalePrice  Total years  \n",
       "0       854     208500           20  \n",
       "1         0     181500           47  \n",
       "2       866     223500           22  \n",
       "3       756     140000          108  \n",
       "4      1053     250000           23  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating categorical features for classfications with less number of variations\n",
    "cat_features=['MSSubClass', 'MSZoning', 'Street', 'LotShape']\n",
    "out_feature='SalePrice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to convert the numerical values to categorical features, we use LabelEncoder\n",
    "#labelencoder provides a way of ranking here\n",
    "#Label encoding used in place of one hot encoding because we will further apply embedding layers by assigning unique index \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# lbl_encoders={}\n",
    "# lbl_encoders['MSSubClass']=LabelEncoder()\n",
    "# lbl_encoders[\"MSSubClass\"].fit_transform(df[\"MSSubClass\"])\n",
    "\n",
    "\n",
    "\n",
    "#example applied to MSSubClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying label encoding to all categorical features\n",
    "label_encoders={}\n",
    "for i in range(len(cat_features)):\n",
    "    label_encoders[cat_features[i]]=LabelEncoder()\n",
    "    df[cat_features[i]]=label_encoders[cat_features[i]].fit_transform(df[cat_features[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Total years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>208500</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>223500</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>140000</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>250000</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>953</td>\n",
       "      <td>694</td>\n",
       "      <td>175000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>210000</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1188</td>\n",
       "      <td>1152</td>\n",
       "      <td>266500</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1078</td>\n",
       "      <td>0</td>\n",
       "      <td>142125</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1256</td>\n",
       "      <td>0</td>\n",
       "      <td>147500</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1201 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  MSZoning  LotFrontage  LotArea  Street  LotShape  1stFlrSF  \\\n",
       "0              5         3         65.0     8450       1         3       856   \n",
       "1              0         3         80.0     9600       1         3      1262   \n",
       "2              5         3         68.0    11250       1         0       920   \n",
       "3              6         3         60.0     9550       1         0       961   \n",
       "4              5         3         84.0    14260       1         0      1145   \n",
       "...          ...       ...          ...      ...     ...       ...       ...   \n",
       "1455           5         3         62.0     7917       1         3       953   \n",
       "1456           0         3         85.0    13175       1         3      2073   \n",
       "1457           6         3         66.0     9042       1         3      1188   \n",
       "1458           0         3         68.0     9717       1         3      1078   \n",
       "1459           0         3         75.0     9937       1         3      1256   \n",
       "\n",
       "      2ndFlrSF  SalePrice  Total years  \n",
       "0          854     208500           20  \n",
       "1            0     181500           47  \n",
       "2          866     223500           22  \n",
       "3          756     140000          108  \n",
       "4         1053     250000           23  \n",
       "...        ...        ...          ...  \n",
       "1455       694     175000           24  \n",
       "1456         0     210000           45  \n",
       "1457      1152     266500           82  \n",
       "1458         0     142125           73  \n",
       "1459         0     147500           58  \n",
       "\n",
       "[1201 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 3, 1, 3],\n",
       "       [0, 3, 1, 3],\n",
       "       [5, 3, 1, 0],\n",
       "       ...,\n",
       "       [6, 3, 1, 3],\n",
       "       [0, 3, 1, 3],\n",
       "       [0, 3, 1, 3]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features=np.stack([df['MSSubClass'], df['MSZoning'], df['Street'], df['LotShape']],1)\n",
    "cat_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotFrontage', 'LotArea', '1stFlrSF', '2ndFlrSF', 'Total years']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_features=[]\n",
    "for i in df.columns:\n",
    "    if i in['MSSubClass', 'MSZoning', 'Street', 'LotShape', 'SalePrice']:\n",
    "        pass\n",
    "    else:\n",
    "        continuous_features.append(i)\n",
    "\n",
    "continuous_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we use pytorch to actually stack the continuous varibles to a tensor\n",
    "continuous_values=np.stack([df[i].values for i in continuous_features], axis=1)\n",
    "cont_values=torch.tensor(continuous_values, dtype=torch.float)\n",
    "\n",
    "#int cannot be used tfor continuous values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_values.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[208500.],\n",
       "        [181500.],\n",
       "        [223500.],\n",
       "        ...,\n",
       "        [266500.],\n",
       "        [142125.],\n",
       "        [147500.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting target/ SalePrice to tensors as well\n",
    "\n",
    "y=torch.tensor(df['SalePrice'].values, dtype=torch.float).reshape(-1,1)\n",
    "y\n",
    "#reshaping done to prevent one dim array formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1201, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1201, 4), (1201, 5), torch.Size([1201, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "cat_features.shape, continuous_values.shape, y.shape\n",
    "\n",
    "#this is a good practice to proofread whether the dataset prepared is correct ot not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15, 8), (5, 3), (2, 1), (4, 2)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embedding for categorical features\n",
    "\n",
    "cat_dims=[len(df[cols].unique()) for cols in [\"MSSubClass\", \"MSZoning\", \"Street\", \"LotShape\"]]\n",
    "\n",
    "\n",
    "#embedding output dimensions, for rule refer to fast.ai \n",
    "embedding_dim=[(x, min(50, (x+1)//2)) for x in cat_dims]\n",
    "embedding_dim\n",
    "\n",
    "##data pre processing steps until here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(15, 8)\n",
       "  (1): Embedding(5, 3)\n",
       "  (2): Embedding(2, 1)\n",
       "  (3): Embedding(4, 2)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "embed_representation=nn.ModuleList([nn.Embedding(inp,out) for inp,out in embedding_dim])\n",
    "embed_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [5, 3, 1, 0],\n",
       "        [6, 3, 1, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features=torch.tensor(cat_features, dtype=torch.int)\n",
    "\n",
    "cat_featuresz=cat_features[:4]\n",
    "cat_featuresz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [5, 3, 1, 0],\n",
       "        ...,\n",
       "        [6, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [0, 3, 1, 3]], dtype=torch.int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features\n",
    "\n",
    "#column wise output for each categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have to convert it into embedding vectors\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "embedding_val=[]\n",
    "\n",
    "for i,e in enumerate(embed_representation):\n",
    "    embedding_val.append(e(cat_features[:,i]))\n",
    "\n",
    "#passing whole column records for converting to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-1.2513, -0.2544,  0.4364,  ..., -1.8865,  0.0282,  0.8068],\n",
       "         [ 1.8036,  0.3069, -0.7143,  ...,  0.7770, -0.4858,  1.3633],\n",
       "         [-1.2513, -0.2544,  0.4364,  ..., -1.8865,  0.0282,  0.8068],\n",
       "         ...,\n",
       "         [ 0.2922,  3.3085, -0.4740,  ...,  0.4278, -1.0475,  0.0230],\n",
       "         [ 1.8036,  0.3069, -0.7143,  ...,  0.7770, -0.4858,  1.3633],\n",
       "         [ 1.8036,  0.3069, -0.7143,  ...,  0.7770, -0.4858,  1.3633]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[-0.1652, -0.0255,  0.9296],\n",
       "         [-0.1652, -0.0255,  0.9296],\n",
       "         [-0.1652, -0.0255,  0.9296],\n",
       "         ...,\n",
       "         [-0.1652, -0.0255,  0.9296],\n",
       "         [-0.1652, -0.0255,  0.9296],\n",
       "         [-0.1652, -0.0255,  0.9296]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[-0.7709],\n",
       "         [-0.7709],\n",
       "         [-0.7709],\n",
       "         ...,\n",
       "         [-0.7709],\n",
       "         [-0.7709],\n",
       "         [-0.7709]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[ 0.3944, -1.2331],\n",
       "         [ 0.3944, -1.2331],\n",
       "         [ 0.6964, -0.0201],\n",
       "         ...,\n",
       "         [ 0.3944, -1.2331],\n",
       "         [ 0.3944, -1.2331],\n",
       "         [ 0.3944, -1.2331]], grad_fn=<EmbeddingBackward0>)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_val\n",
    "\n",
    "#the first feature is represented by 8 dimensions, the second by 8 dimesions and so forth for the values of the first column\n",
    "#since from the dimensions 15 as input and 8 as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [5, 3, 1, 0],\n",
       "        [6, 3, 1, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_featuresz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-1.2513, -0.2544,  0.4364,  ..., -1.8865,  0.0282,  0.8068],\n",
       "         [ 1.8036,  0.3069, -0.7143,  ...,  0.7770, -0.4858,  1.3633],\n",
       "         [-1.2513, -0.2544,  0.4364,  ..., -1.8865,  0.0282,  0.8068],\n",
       "         ...,\n",
       "         [ 0.2922,  3.3085, -0.4740,  ...,  0.4278, -1.0475,  0.0230],\n",
       "         [ 1.8036,  0.3069, -0.7143,  ...,  0.7770, -0.4858,  1.3633],\n",
       "         [ 1.8036,  0.3069, -0.7143,  ...,  0.7770, -0.4858,  1.3633]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[-0.1652, -0.0255,  0.9296],\n",
       "         [-0.1652, -0.0255,  0.9296],\n",
       "         [-0.1652, -0.0255,  0.9296],\n",
       "         ...,\n",
       "         [-0.1652, -0.0255,  0.9296],\n",
       "         [-0.1652, -0.0255,  0.9296],\n",
       "         [-0.1652, -0.0255,  0.9296]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[-0.7709],\n",
       "         [-0.7709],\n",
       "         [-0.7709],\n",
       "         ...,\n",
       "         [-0.7709],\n",
       "         [-0.7709],\n",
       "         [-0.7709]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[ 0.3944, -1.2331],\n",
       "         [ 0.3944, -1.2331],\n",
       "         [ 0.6964, -0.0201],\n",
       "         ...,\n",
       "         [ 0.3944, -1.2331],\n",
       "         [ 0.3944, -1.2331],\n",
       "         [ 0.3944, -1.2331]], grad_fn=<EmbeddingBackward0>)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2513, -0.2544,  0.4364,  ..., -0.7709,  0.3944, -1.2331],\n",
       "        [ 1.8036,  0.3069, -0.7143,  ..., -0.7709,  0.3944, -1.2331],\n",
       "        [-1.2513, -0.2544,  0.4364,  ..., -0.7709,  0.6964, -0.0201],\n",
       "        ...,\n",
       "        [ 0.2922,  3.3085, -0.4740,  ..., -0.7709,  0.3944, -1.2331],\n",
       "        [ 1.8036,  0.3069, -0.7143,  ..., -0.7709,  0.3944, -1.2331],\n",
       "        [ 1.8036,  0.3069, -0.7143,  ..., -0.7709,  0.3944, -1.2331]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the stacking for embedded values is still improper\n",
    "z=torch.cat(embedding_val, axis=1)\n",
    "z\n",
    "\n",
    "#values are appended to the end of each row for the tensors, actually similar to the stacking in numpy but pytorch provides functionality directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout=nn.Dropout(0.4)\n",
    "\n",
    "final_embed=dropout(z)\n",
    "#used to prevent the neurons from overfitting\n",
    "#using dropout prevents all the neurons in a layer from synchronously optimizing their weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_dummies in module pandas.core.reshape.encoding:\n",
      "\n",
      "get_dummies(data, prefix=None, prefix_sep: 'str | Iterable[str] | dict[str, str]' = '_', dummy_na: 'bool' = False, columns=None, sparse: 'bool' = False, drop_first: 'bool' = False, dtype: 'NpDtype | None' = None) -> 'DataFrame'\n",
      "    Convert categorical variable into dummy/indicator variables.\n",
      "    \n",
      "    Each variable is converted in as many 0/1 variables as there are different\n",
      "    values. Columns in the output are each named after a value; if the input is\n",
      "    a DataFrame, the name of the original variable is prepended to the value.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    data : array-like, Series, or DataFrame\n",
      "        Data of which to get dummy indicators.\n",
      "    prefix : str, list of str, or dict of str, default None\n",
      "        String to append DataFrame column names.\n",
      "        Pass a list with length equal to the number of columns\n",
      "        when calling get_dummies on a DataFrame. Alternatively, `prefix`\n",
      "        can be a dictionary mapping column names to prefixes.\n",
      "    prefix_sep : str, default '_'\n",
      "        If appending prefix, separator/delimiter to use. Or pass a\n",
      "        list or dictionary as with `prefix`.\n",
      "    dummy_na : bool, default False\n",
      "        Add a column to indicate NaNs, if False NaNs are ignored.\n",
      "    columns : list-like, default None\n",
      "        Column names in the DataFrame to be encoded.\n",
      "        If `columns` is None then all the columns with\n",
      "        `object`, `string`, or `category` dtype will be converted.\n",
      "    sparse : bool, default False\n",
      "        Whether the dummy-encoded columns should be backed by\n",
      "        a :class:`SparseArray` (True) or a regular NumPy array (False).\n",
      "    drop_first : bool, default False\n",
      "        Whether to get k-1 dummies out of k categorical levels by removing the\n",
      "        first level.\n",
      "    dtype : dtype, default bool\n",
      "        Data type for new columns. Only a single dtype is allowed.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        Dummy-coded data. If `data` contains other columns than the\n",
      "        dummy-coded one(s), these will be prepended, unaltered, to the result.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    Series.str.get_dummies : Convert Series of strings to dummy codes.\n",
      "    :func:`~pandas.from_dummies` : Convert dummy codes to categorical ``DataFrame``.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Reference :ref:`the user guide <reshaping.dummies>` for more examples.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> s = pd.Series(list('abca'))\n",
      "    \n",
      "    >>> pd.get_dummies(s)\n",
      "           a      b      c\n",
      "    0   True  False  False\n",
      "    1  False   True  False\n",
      "    2  False  False   True\n",
      "    3   True  False  False\n",
      "    \n",
      "    >>> s1 = ['a', 'b', np.nan]\n",
      "    \n",
      "    >>> pd.get_dummies(s1)\n",
      "           a      b\n",
      "    0   True  False\n",
      "    1  False   True\n",
      "    2  False  False\n",
      "    \n",
      "    >>> pd.get_dummies(s1, dummy_na=True)\n",
      "           a      b    NaN\n",
      "    0   True  False  False\n",
      "    1  False   True  False\n",
      "    2  False  False   True\n",
      "    \n",
      "    >>> df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['b', 'a', 'c'],\n",
      "    ...                    'C': [1, 2, 3]})\n",
      "    \n",
      "    >>> pd.get_dummies(df, prefix=['col1', 'col2'])\n",
      "       C  col1_a  col1_b  col2_a  col2_b  col2_c\n",
      "    0  1    True   False   False    True   False\n",
      "    1  2   False    True    True   False   False\n",
      "    2  3    True   False   False   False    True\n",
      "    \n",
      "    >>> pd.get_dummies(pd.Series(list('abcaa')))\n",
      "           a      b      c\n",
      "    0   True  False  False\n",
      "    1  False   True  False\n",
      "    2  False  False   True\n",
      "    3   True  False  False\n",
      "    4   True  False  False\n",
      "    \n",
      "    >>> pd.get_dummies(pd.Series(list('abcaa')), drop_first=True)\n",
      "           b      c\n",
      "    0  False  False\n",
      "    1   True  False\n",
      "    2  False   True\n",
      "    3  False  False\n",
      "    4  False  False\n",
      "    \n",
      "    >>> pd.get_dummies(pd.Series(list('abc')), dtype=float)\n",
      "         a    b    c\n",
      "    0  1.0  0.0  0.0\n",
      "    1  0.0  1.0  0.0\n",
      "    2  0.0  0.0  1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.get_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a class for a neural network\n",
    "#nn.Module is required to inherit to create sequential neural networks\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embedding_dim, n_cont, out_sz, layers, p):\n",
    "        super().__init__()\n",
    "        self.embeds=nn.ModuleList([nn.Embedding(inp,out) for inp,out in embedding_dim])\n",
    "        self.emb_drop=nn.Dropout(p)\n",
    "        self.bn_count=nn.BatchNorm1d(n_cont)\n",
    "        #batch normalizaiton for continuos variables only\n",
    "\n",
    "        \n",
    "        layerlist=[]\n",
    "        n_emb=sum((out for inp,out in embedding_dim))\n",
    "        n_in=n_emb+n_cont\n",
    "\n",
    "        #total output from embedding features and total inputs from continuous features\n",
    "\n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i))\n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "\n",
    "            n_in=i\n",
    "\n",
    "        layerlist.append(nn.Linear(layers[-1], out_sz))\n",
    "\n",
    "        #wrapping all the layers' list now into sequantial layer\n",
    "        self.layers=nn.Sequential(*layerlist)\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings=[]\n",
    "\n",
    "        #creating the embeddings\n",
    "\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        #concatenating the embeddings\n",
    "        #then applying a dropout layer\n",
    "        x=torch.cat(embeddings, 1)\n",
    "        x=self.emb_drop(x)\n",
    "\n",
    "        x_cont=self.bn_count(x_cont)\n",
    "        #now concatenating all the input as well as continuous features\n",
    "        x=torch.cat([x,x_cont], 1)\n",
    "        x=self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(continuous_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1000)\n",
    "model=FeedForward(embedding_dim, len(continuous_features), 1, [100, 50],p=0.4)\n",
    "\n",
    "#initializing two layers with 100 neurons and 50 neurons respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedForward(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(15, 8)\n",
       "    (1): Embedding(5, 3)\n",
       "    (2): Embedding(2, 1)\n",
       "    (3): Embedding(4, 2)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_count): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=19, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=nn.MSELoss()\n",
    "\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1201, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1201, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing a train test split on the dataset\n",
    "#usual train_test_split from sklearn.model_selection does not work because here we have tensors unlike values in a usual dataset\n",
    "\n",
    "batch_size=1200\n",
    "test_size=int(batch_size *0.15)\n",
    "train_categorical=cat_features[:batch_size - test_size]\n",
    "test_categorical=cat_features[batch_size-test_size: batch_size]\n",
    "train_cont=cont_values[:batch_size - test_size]\n",
    "test_cont=cont_values[batch_size - test_size:batch_size]\n",
    "\n",
    "y_train=y[:batch_size - test_size]\n",
    "y_test=y[batch_size-test_size: batch_size]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1020, 180, 1020, 180)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_categorical), len(test_categorical), len(train_cont), len(test_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number1000 and loss is 184412.625\n"
     ]
    }
   ],
   "source": [
    "epochs=5000\n",
    "final_losses=[]\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred=model(train_categorical, train_cont)\n",
    "    losses=torch.sqrt(loss(y_pred, y_train))\n",
    "    final_losses.append(losses)\n",
    "\n",
    "    if i%1000==0:\n",
    "        print(f\"Epoch number{i} and loss is {losses.item()}\")\n",
    "    optimizer.zero_grad()\n",
    "    losses.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m plt\u001b[39m.\u001b[39mplot(\u001b[39mrange\u001b[39m(epochs), final_losses)\n\u001b[1;32m      4\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mnumber of epochs\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mRMSE loss\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(epochs), final_losses)\n",
    "plt.xlabel('number of epochs')\n",
    "plt.ylabel('RMSE loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m y_pred\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      3\u001b[0m     y_pred\u001b[39m=\u001b[39mmodel(test_categorical, test_cont)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred=\"\"\n",
    "with torch.no_grad():\n",
    "    y_pred=model(test_categorical, test_cont)\n",
    "    loss=torch.sqrt(y_pred, y_test)\n",
    "\n",
    "print(f\"Rmse{losses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_verify\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame(y_test\u001b[39m.\u001b[39mtolist(), columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mactual data\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m data_predicted\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame(y_pred\u001b[39m.\u001b[39mtolist(), columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mpredicted data\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m final_output\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mconcat([data_verify, data_predicted], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data_verify=pd.DataFrame(y_test.tolist(), columns=['actual data'])\n",
    "data_predicted=pd.DataFrame(y_pred.tolist(), columns=['predicted data'])\n",
    "final_output=pd.concat([data_verify, data_predicted], axis=1)\n",
    "final_output['Difference']=final_output['actual data']-final_output['predicted data']\n",
    "final_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#the model can be saved as\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m torch\u001b[39m.\u001b[39msave(model, \u001b[39m'\u001b[39m\u001b[39mHousePriceUsingDeepLearning.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39m#the weights of the model can be saved as\u001b[39;00m\n\u001b[1;32m      5\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), \u001b[39m'\u001b[39m\u001b[39mHousePriceUsingDeepLearning.pt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#the model can be saved as\n",
    "torch.save(model, 'HousePriceUsingDeepLearning.pt')\n",
    "\n",
    "#the weights of the model can be saved as\n",
    "torch.save(model.state_dict(), 'HousePriceUsingDeepLearning.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FeedForward' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#now, the saved model can be loaded as\u001b[39;00m\n\u001b[1;32m      3\u001b[0m embs_size\u001b[39m=\u001b[39m[(\u001b[39m15\u001b[39m, \u001b[39m8\u001b[39m), (\u001b[39m5\u001b[39m,\u001b[39m3\u001b[39m), (\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m), (\u001b[39m4\u001b[39m,\u001b[39m2\u001b[39m)]\n\u001b[0;32m----> 4\u001b[0m model1\u001b[39m=\u001b[39mFeedForward(embs_size, \u001b[39m5\u001b[39m, \u001b[39m1\u001b[39m, [\u001b[39m100\u001b[39m, \u001b[39m50\u001b[39m], p\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[1;32m      5\u001b[0m model1\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mHousePriceUsingDeepLearning.pt\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FeedForward' is not defined"
     ]
    }
   ],
   "source": [
    "#now, the saved model can be loaded as\n",
    "\n",
    "embs_size=[(15, 8), (5,3), (2,1), (4,2)]\n",
    "model1=FeedForward(embs_size, 5, 1, [100, 50], p=0.5)\n",
    "model1.load_state_dict(torch.load('HousePriceUsingDeepLearning.pt'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.eval()\n",
    "#rerun everything again\n",
    "#outputs must be the same as while loading the model at class definition "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
